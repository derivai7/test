{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7Gn9y+GSB59zynou7WGeI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/derivai7/test/blob/main/05_BahtiarRifa'i_P12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bahtiar Rifa'i/05/2B/Pertemuan 12"
      ],
      "metadata": {
        "id": "PxwlRIQkwb9y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hmWQEHDcck2x",
        "outputId": "111ffbd4-04f9-4209-eeae-0adff929c3a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'outlook': 0.24674981977443955,\n",
              " 'temp': 0.029222565658955313,\n",
              " 'humidity': 0.15183550136234203,\n",
              " 'windy': 0.04812703040826993}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "eps = np.finfo(float).eps\n",
        "from numpy import log2 as log\n",
        "\n",
        "outlook = 'overcast, overcast,overcast,overcast,rainy,rainy,rainy,rainy,rainy,sunny,sunny,sunny,sunny,sunny'.split(',')\n",
        "temp = 'hot,cool,mild,hot,mild,cool,cool,mild,mild,hot,hot,mild,cool,mild'.split(',')\n",
        "humidity = 'high,normal,high,normal,high,normal,normal,normal,high,high,high,high,normal,normal'.split(',')\n",
        "windy = 'FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,TRUE'.split(',')\n",
        "play = 'yes,yes,yes,yes,yes,yes,no,yes,no,no,no,no,yes,yes'.split(',')\n",
        "\n",
        "dataset = {'outlook' : outlook, 'temp' : temp, 'humidity' : humidity, 'windy' : windy, 'play' : play}\n",
        "df = pd.DataFrame(dataset,columns=['outlook', 'temp', 'humidity', 'windy','play'])\n",
        "\n",
        "##1. calculate entropy o the whole dataset\n",
        "entropy_node = 0 #Initialize Entropy\n",
        "values = df.play.unique() #Unique Objects - 'Yes', 'No'\n",
        "for value in values :\n",
        "  fraction = df.play.value_counts()[value]/len(df.play)\n",
        "  entropy_node += -fraction*np.log2(fraction)\n",
        "entropy_node\n",
        "\n",
        "def ent(df,attribute):\n",
        "  target_variables = df.play.unique()\n",
        "  variables = df[attribute].unique()\n",
        "\n",
        "  entropy_attribute = 0\n",
        "  for variable in variables :\n",
        "    entropy_each_feature = 0\n",
        "    for target_variable in target_variables :\n",
        "      num = len(df[attribute][df[attribute]==variable][df.play == target_variable])\n",
        "      den = len(df[attribute][df[attribute]==variable])\n",
        "      fraction = num/(den+eps)\n",
        "      entropy_each_feature += fraction*log(fraction+eps)\n",
        "    fraction2 = den/len(df)\n",
        "    entropy_attribute +=-fraction2*entropy_each_feature\n",
        "  return(abs(entropy_attribute))\n",
        "\n",
        "a_entropy = {k:ent(df,k) for k in df.keys()[:-1]}\n",
        "a_entropy\n",
        "\n",
        "def ig(e_dataset,e_attr):\n",
        "  return(e_dataset-e_attr)\n",
        "\n",
        "IG = {k:ig(entropy_node,a_entropy[k]) for k in a_entropy}\n",
        "IG"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now to proceed our tree we will use recursion\n",
        "\n",
        "def find_entropy(df):\n",
        "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
        "    entropy = 0\n",
        "    values = df[Class].unique()\n",
        "    for value in values:\n",
        "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
        "        entropy += -fraction*np.log2(fraction)\n",
        "    return entropy\n",
        "  \n",
        "  \n",
        "def find_entropy_attribute(df,attribute):\n",
        "  Class = df.keys()[-1]   \n",
        "  target_variables = df[Class].unique()  \n",
        "  variables = df[attribute].unique()    \n",
        "  entropy2 = 0\n",
        "  for variable in variables:\n",
        "      entropy = 0\n",
        "      for target_variable in target_variables:\n",
        "          num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
        "          den = len(df[attribute][df[attribute]==variable])\n",
        "          fraction = num/(den+eps)\n",
        "          entropy += -fraction*log(fraction+eps)\n",
        "      fraction2 = den/len(df)\n",
        "      entropy2 += -fraction2*entropy\n",
        "  return abs(entropy2)\n",
        "\n",
        "\n",
        "def find_winner(df):\n",
        "    Entropy_att = []\n",
        "    IG = []\n",
        "    for key in df.keys()[:-1]:\n",
        "        IG.append(find_entropy(df)-find_entropy_attribute(df,key))\n",
        "    return df.keys()[:-1][np.argmax(IG)]\n",
        "  \n",
        "  \n",
        "def get_subtable(df, node,value):\n",
        "  return df[df[node] == value].reset_index(drop=True)\n",
        "\n",
        "\n",
        "def buildTree(df,tree=None): \n",
        "    Class = df.keys()[-1]  \n",
        "    node = find_winner(df)\n",
        "    attValue = np.unique(df[node])  \n",
        "    if tree is None:                    \n",
        "        tree={}\n",
        "        tree[node] = {}\n",
        "    for value in attValue:\n",
        "        subtable = get_subtable(df,node,value)\n",
        "        clValue,counts = np.unique(subtable[Class],return_counts=True)                        \n",
        "        if len(counts)==1:\n",
        "            tree[node][value] = clValue[0]                                                    \n",
        "        else:        \n",
        "            tree[node][value] = buildTree(subtable) \n",
        "                   \n",
        "    return tree"
      ],
      "metadata": {
        "id": "IklJBEAMs_L-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pprintpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eiTN_gkxpDdw",
        "outputId": "2eaa5d21-b32b-4578-b5ab-f22c7744b768"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pprintpp in /usr/local/lib/python3.7/dist-packages (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = buildTree(df)\n",
        "import pprint\n",
        "pprint.pprint(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1-OVODx8pHj3",
        "outputId": "42d1f123-ccad-47c8-993d-7c062580ac7a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'outlook': {' overcast': 'yes',\n",
            "             'overcast': 'yes',\n",
            "             'rainy': {'windy': {'FALSE': 'yes', 'TRUE': 'no'}},\n",
            "             'sunny': {'humidity': {'high': 'no', 'normal': 'yes'}}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apakah rumus entropy di Materi dan di Jobsheet berbeda?\n",
        "Jawab: tidak karena di materi menggunakan algoritma C4.5, sefangkan di Jobsheet menggunakan algoritma ID3"
      ],
      "metadata": {
        "id": "u6u-IyrcvSzP"
      }
    }
  ]
}